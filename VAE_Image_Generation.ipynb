{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Variational Autoencoder (VAE) for Image Generation\n",
        "\n",
        "**Author:** Molla Samser  \n",
        "**Website:** https://rskworld.in  \n",
        "**Email:** help@rskworld.in, support@rskworld.in  \n",
        "**Phone:** +91 93305 39277  \n",
        "**Designer & Tester:** Rima Khatun\n",
        "\n",
        "This notebook demonstrates how to train and use a Variational Autoencoder for image generation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image, make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from vae_model import VAE, vae_loss\n",
        "from utils import save_reconstructions, visualize_latent_space\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load and Prepare Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # For MNIST (grayscale)\n",
        "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # For CIFAR10 (RGB)\n",
        "])\n",
        "\n",
        "# Load dataset (MNIST example)\n",
        "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "print(f'Training samples: {len(train_dataset)}')\n",
        "print(f'Test samples: {len(test_dataset)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initialize Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model parameters\n",
        "latent_dim = 128\n",
        "input_channels = 1  # 1 for MNIST, 3 for CIFAR10\n",
        "\n",
        "# Initialize model\n",
        "model = VAE(input_channels=input_channels, latent_dim=latent_dim).to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f'Total parameters: {total_params:,}')\n",
        "print(f'Model architecture:')\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, dataloader, optimizer, device, beta=1.0):\n",
        "    \"\"\"\n",
        "    Train the model for one epoch.\n",
        "    \n",
        "    Author: Molla Samser\n",
        "    Website: https://rskworld.in\n",
        "    Email: help@rskworld.in, support@rskworld.in\n",
        "    Phone: +91 93305 39277\n",
        "    Designer & Tester: Rima Khatun\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_recon_loss = 0\n",
        "    total_kl_loss = 0\n",
        "    \n",
        "    for batch_idx, (data, _) in enumerate(dataloader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        reconstructed, mu, logvar, z = model(data)\n",
        "        \n",
        "        # Calculate loss\n",
        "        loss, recon_loss, kl_loss = vae_loss(reconstructed, data, mu, logvar, beta)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        total_recon_loss += recon_loss.item()\n",
        "        total_kl_loss += kl_loss.item()\n",
        "    \n",
        "    avg_loss = total_loss / len(dataloader.dataset)\n",
        "    avg_recon = total_recon_loss / len(dataloader.dataset)\n",
        "    avg_kl = total_kl_loss / len(dataloader.dataset)\n",
        "    \n",
        "    return avg_loss, avg_recon, avg_kl\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training parameters\n",
        "num_epochs = 50\n",
        "learning_rate = 1e-3\n",
        "beta = 1.0  # KL divergence weight\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training history\n",
        "train_losses = []\n",
        "train_recon_losses = []\n",
        "train_kl_losses = []\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs('outputs/samples', exist_ok=True)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
        "    print('-' * 50)\n",
        "    \n",
        "    # Train\n",
        "    train_loss, train_recon, train_kl = train_epoch(model, train_loader, optimizer, device, beta)\n",
        "    train_losses.append(train_loss)\n",
        "    train_recon_losses.append(train_recon)\n",
        "    train_kl_losses.append(train_kl)\n",
        "    \n",
        "    print(f'Train Loss: {train_loss:.4f}, Recon: {train_recon:.4f}, KL: {train_kl:.4f}')\n",
        "    \n",
        "    # Generate samples every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            # Generate from random latent vectors\n",
        "            samples = model.generate(num_samples=64, device=device)\n",
        "            save_image(samples, f'outputs/samples/epoch_{epoch+1}.png', nrow=8, normalize=True)\n",
        "            \n",
        "            # Reconstruct some test images\n",
        "            test_data, _ = next(iter(test_loader))\n",
        "            test_data = test_data[:8].to(device)\n",
        "            recon_data, _, _, _ = model(test_data)\n",
        "            comparison = torch.cat([test_data, recon_data], dim=0)\n",
        "            save_image(comparison, f'outputs/samples/recon_epoch_{epoch+1}.png', nrow=8, normalize=True)\n",
        "        \n",
        "        print(f'Samples saved for epoch {epoch+1}')\n",
        "\n",
        "print('\\nTraining completed!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualize Training Progress\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(train_losses)\n",
        "plt.title('Total Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(train_recon_losses)\n",
        "plt.title('Reconstruction Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(train_kl_losses)\n",
        "plt.title('KL Divergence Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/training_curves.png', dpi=150)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Generate New Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate new images from random latent vectors\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    generated = model.generate(num_samples=64, device=device)\n",
        "\n",
        "# Display generated images\n",
        "grid = make_grid(generated, nrow=8, normalize=True)\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.imshow(grid.permute(1, 2, 0).cpu())\n",
        "plt.axis('off')\n",
        "plt.title('Generated Images from Random Latent Vectors')\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/generated_images.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Image Reconstruction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reconstruct test images\n",
        "model.eval()\n",
        "test_data, _ = next(iter(test_loader))\n",
        "test_data = test_data[:16].to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    reconstructed, mu, logvar, z = model(test_data)\n",
        "\n",
        "# Display original vs reconstructed\n",
        "comparison = torch.cat([test_data, reconstructed], dim=0)\n",
        "grid = make_grid(comparison, nrow=8, normalize=True)\n",
        "plt.figure(figsize=(15, 8))\n",
        "plt.imshow(grid.permute(1, 2, 0).cpu())\n",
        "plt.axis('off')\n",
        "plt.title('Original (top) vs Reconstructed (bottom)')\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/reconstruction_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Latent Space Interpolation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interpolate between two random points in latent space\n",
        "model.eval()\n",
        "num_steps = 10\n",
        "\n",
        "z1 = torch.randn(1, latent_dim).to(device)\n",
        "z2 = torch.randn(1, latent_dim).to(device)\n",
        "\n",
        "alphas = torch.linspace(0, 1, num_steps).to(device)\n",
        "interpolated_images = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for alpha in alphas:\n",
        "        z_interp = (1 - alpha) * z1 + alpha * z2\n",
        "        img = model.decoder(z_interp)\n",
        "        interpolated_images.append(img)\n",
        "\n",
        "# Display interpolation\n",
        "result = torch.cat(interpolated_images, dim=0)\n",
        "grid = make_grid(result, nrow=num_steps, normalize=True)\n",
        "plt.figure(figsize=(15, 2))\n",
        "plt.imshow(grid.permute(1, 2, 0).cpu())\n",
        "plt.axis('off')\n",
        "plt.title('Latent Space Interpolation')\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/interpolation.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Save Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save trained model\n",
        "torch.save(model.state_dict(), 'vae_model.pth')\n",
        "print('Model saved to vae_model.pth')\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
